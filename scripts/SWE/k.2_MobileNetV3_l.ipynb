{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ae13e9-2b65-4e62-9610-38928409afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, matthews_corrcoef, recall_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torchvision.models as models\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from typing import Callable, Optional\n",
    "from torch import Tensor\n",
    "\n",
    "from typing import Callable, List, Optional\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7524b75f-c06f-4b59-ae6a-5274de437689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_873/4225776391.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_datasets_info = torch.load('/root/autodl-tmp/imgs/SWE/saved_datasets_SWE.pth')\n"
     ]
    }
   ],
   "source": [
    "loaded_datasets_info = torch.load('/root/autodl-tmp/imgs/SWE/saved_datasets_SWE.pth')\n",
    "train_dataset = loaded_datasets_info['train_dataset']\n",
    "val_dataset = loaded_datasets_info['val_dataset']\n",
    "test_dataset = loaded_datasets_info['test_dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d070bec3-d4ab-478f-b5a6-571f39a069b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "loaded_train_dataset = DataLoader(train_dataset, batch_size = batch_size, shuffle = False)\n",
    "loaded_val_dataset = DataLoader(val_dataset, batch_size = batch_size, shuffle = False)\n",
    "loaded_test_dataset = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd77db92-43c1-4688-b947-fa83daa3c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(ch, divisor=8, min_ch=None):\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    \"\"\"\n",
    "    if min_ch is None:\n",
    "        min_ch = divisor\n",
    "    new_ch = max(min_ch, int(ch + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_ch < 0.9 * ch:\n",
    "        new_ch += divisor\n",
    "    return new_ch\n",
    "\n",
    "\n",
    "class ConvBNActivation(nn.Sequential):\n",
    "    def __init__(self,\n",
    "                 in_planes: int,\n",
    "                 out_planes: int,\n",
    "                 kernel_size: int = 3,\n",
    "                 stride: int = 1,\n",
    "                 groups: int = 1,\n",
    "                 norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "                 activation_layer: Optional[Callable[..., nn.Module]] = None):\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if activation_layer is None:\n",
    "            activation_layer = nn.ReLU6\n",
    "        super(ConvBNActivation, self).__init__(nn.Conv2d(in_channels=in_planes,\n",
    "                                                         out_channels=out_planes,\n",
    "                                                         kernel_size=kernel_size,\n",
    "                                                         stride=stride,\n",
    "                                                         padding=padding,\n",
    "                                                         groups=groups,\n",
    "                                                         bias=False),\n",
    "                                               norm_layer(out_planes),\n",
    "                                               activation_layer(inplace=True))\n",
    "\n",
    "\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    def __init__(self, input_c: int, squeeze_factor: int = 4):\n",
    "        super(SqueezeExcitation, self).__init__()\n",
    "        squeeze_c = _make_divisible(input_c // squeeze_factor, 8)\n",
    "        self.fc1 = nn.Conv2d(input_c, squeeze_c, 1)\n",
    "        self.fc2 = nn.Conv2d(squeeze_c, input_c, 1)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        scale = F.adaptive_avg_pool2d(x, output_size=(1, 1))\n",
    "        scale = self.fc1(scale)\n",
    "        scale = F.relu(scale, inplace=True)\n",
    "        scale = self.fc2(scale)\n",
    "        scale = F.hardsigmoid(scale, inplace=True)\n",
    "        return scale * x\n",
    "\n",
    "\n",
    "class InvertedResidualConfig:\n",
    "    def __init__(self,\n",
    "                 input_c: int,\n",
    "                 kernel: int,\n",
    "                 expanded_c: int,\n",
    "                 out_c: int,\n",
    "                 use_se: bool,\n",
    "                 activation: str,\n",
    "                 stride: int,\n",
    "                 width_multi: float):\n",
    "        self.input_c = self.adjust_channels(input_c, width_multi)\n",
    "        self.kernel = kernel\n",
    "        self.expanded_c = self.adjust_channels(expanded_c, width_multi)\n",
    "        self.out_c = self.adjust_channels(out_c, width_multi)\n",
    "        self.use_se = use_se\n",
    "        self.use_hs = activation == \"HS\"  # whether using h-swish activation\n",
    "        self.stride = stride\n",
    "\n",
    "    @staticmethod\n",
    "    def adjust_channels(channels: int, width_multi: float):\n",
    "        return _make_divisible(channels * width_multi, 8)\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self,\n",
    "                 cnf: InvertedResidualConfig,\n",
    "                 norm_layer: Callable[..., nn.Module]):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "\n",
    "        if cnf.stride not in [1, 2]:\n",
    "            raise ValueError(\"illegal stride value.\")\n",
    "\n",
    "        self.use_res_connect = (cnf.stride == 1 and cnf.input_c == cnf.out_c)\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "        activation_layer = nn.Hardswish if cnf.use_hs else nn.ReLU\n",
    "\n",
    "        # expand\n",
    "        if cnf.expanded_c != cnf.input_c:\n",
    "            layers.append(ConvBNActivation(cnf.input_c,\n",
    "                                           cnf.expanded_c,\n",
    "                                           kernel_size=1,\n",
    "                                           norm_layer=norm_layer,\n",
    "                                           activation_layer=activation_layer))\n",
    "\n",
    "        # depthwise\n",
    "        layers.append(ConvBNActivation(cnf.expanded_c,\n",
    "                                       cnf.expanded_c,\n",
    "                                       kernel_size=cnf.kernel,\n",
    "                                       stride=cnf.stride,\n",
    "                                       groups=cnf.expanded_c,\n",
    "                                       norm_layer=norm_layer,\n",
    "                                       activation_layer=activation_layer))\n",
    "\n",
    "        if cnf.use_se:\n",
    "            layers.append(SqueezeExcitation(cnf.expanded_c))\n",
    "\n",
    "        # project\n",
    "        layers.append(ConvBNActivation(cnf.expanded_c,\n",
    "                                       cnf.out_c,\n",
    "                                       kernel_size=1,\n",
    "                                       norm_layer=norm_layer,\n",
    "                                       activation_layer=nn.Identity))\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "        self.out_channels = cnf.out_c\n",
    "        self.is_strided = cnf.stride > 1\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        result = self.block(x)\n",
    "        if self.use_res_connect:\n",
    "            result += x\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "class MobileNetV3(nn.Module):\n",
    "    def __init__(self,\n",
    "                 inverted_residual_setting: List[InvertedResidualConfig],\n",
    "                 last_channel: int,\n",
    "                 num_classes: int = 1000,\n",
    "                 block: Optional[Callable[..., nn.Module]] = None,\n",
    "                 norm_layer: Optional[Callable[..., nn.Module]] = None):\n",
    "        super(MobileNetV3, self).__init__()\n",
    "\n",
    "        if not inverted_residual_setting:\n",
    "            raise ValueError(\"The inverted_residual_setting should not be empty.\")\n",
    "        elif not (isinstance(inverted_residual_setting, List) and\n",
    "                  all([isinstance(s, InvertedResidualConfig) for s in inverted_residual_setting])):\n",
    "            raise TypeError(\"The inverted_residual_setting should be List[InvertedResidualConfig]\")\n",
    "\n",
    "        if block is None:\n",
    "            block = InvertedResidual\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = partial(nn.BatchNorm2d, eps=0.001, momentum=0.01)\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "\n",
    "        # building first layer\n",
    "        firstconv_output_c = inverted_residual_setting[0].input_c\n",
    "        layers.append(ConvBNActivation(3,\n",
    "                                       firstconv_output_c,\n",
    "                                       kernel_size=3,\n",
    "                                       stride=2,\n",
    "                                       norm_layer=norm_layer,\n",
    "                                       activation_layer=nn.Hardswish))\n",
    "        # building inverted residual blocks\n",
    "        for cnf in inverted_residual_setting:\n",
    "            layers.append(block(cnf, norm_layer))\n",
    "\n",
    "        # building last several layers\n",
    "        lastconv_input_c = inverted_residual_setting[-1].out_c\n",
    "        lastconv_output_c = 6 * lastconv_input_c\n",
    "        layers.append(ConvBNActivation(lastconv_input_c,\n",
    "                                       lastconv_output_c,\n",
    "                                       kernel_size=1,\n",
    "                                       norm_layer=norm_layer,\n",
    "                                       activation_layer=nn.Hardswish))\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(nn.Linear(lastconv_output_c, last_channel),\n",
    "                                        nn.Hardswish(inplace=True),\n",
    "                                        nn.Dropout(p=0.2, inplace=True),\n",
    "                                        nn.Linear(last_channel, num_classes))\n",
    "\n",
    "        # initial weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        x = self.sigmoid(x) # 加在这里了\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "def mobilenet_v3_large(num_classes: int = 1000,\n",
    "                       reduced_tail: bool = False) -> MobileNetV3:\n",
    "    \"\"\"\n",
    "    Constructs a large MobileNetV3 architecture from\n",
    "    \"Searching for MobileNetV3\" <https://arxiv.org/abs/1905.02244>.\n",
    "\n",
    "    weights_link:\n",
    "    https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): number of classes\n",
    "        reduced_tail (bool): If True, reduces the channel counts of all feature layers\n",
    "            between C4 and C5 by 2. It is used to reduce the channel redundancy in the\n",
    "            backbone for Detection and Segmentation.\n",
    "    \"\"\"\n",
    "    width_multi = 1.0\n",
    "    bneck_conf = partial(InvertedResidualConfig, width_multi=width_multi)\n",
    "    adjust_channels = partial(InvertedResidualConfig.adjust_channels, width_multi=width_multi)\n",
    "\n",
    "    reduce_divider = 2 if reduced_tail else 1\n",
    "\n",
    "    inverted_residual_setting = [\n",
    "        # input_c, kernel, expanded_c, out_c, use_se, activation, stride\n",
    "        bneck_conf(16, 3, 16, 16, False, \"RE\", 1),\n",
    "        bneck_conf(16, 3, 64, 24, False, \"RE\", 2),  # C1\n",
    "        bneck_conf(24, 3, 72, 24, False, \"RE\", 1),\n",
    "        bneck_conf(24, 5, 72, 40, True, \"RE\", 2),  # C2\n",
    "        bneck_conf(40, 5, 120, 40, True, \"RE\", 1),\n",
    "        bneck_conf(40, 5, 120, 40, True, \"RE\", 1),\n",
    "        bneck_conf(40, 3, 240, 80, False, \"HS\", 2),  # C3\n",
    "        bneck_conf(80, 3, 200, 80, False, \"HS\", 1),\n",
    "        bneck_conf(80, 3, 184, 80, False, \"HS\", 1),\n",
    "        bneck_conf(80, 3, 184, 80, False, \"HS\", 1),\n",
    "        bneck_conf(80, 3, 480, 112, True, \"HS\", 1),\n",
    "        bneck_conf(112, 3, 672, 112, True, \"HS\", 1),\n",
    "        bneck_conf(112, 5, 672, 160 // reduce_divider, True, \"HS\", 2),  # C4\n",
    "        bneck_conf(160 // reduce_divider, 5, 960 // reduce_divider, 160 // reduce_divider, True, \"HS\", 1),\n",
    "        bneck_conf(160 // reduce_divider, 5, 960 // reduce_divider, 160 // reduce_divider, True, \"HS\", 1),\n",
    "    ]\n",
    "    last_channel = adjust_channels(1280 // reduce_divider)  # C5\n",
    "\n",
    "    return MobileNetV3(inverted_residual_setting=inverted_residual_setting,\n",
    "                       last_channel=last_channel,\n",
    "                       num_classes=num_classes)\n",
    "\n",
    "\n",
    "def mobilenet_v3_small(num_classes: int = 1000,\n",
    "                       reduced_tail: bool = False) -> MobileNetV3:\n",
    "    \"\"\"\n",
    "    Constructs a large MobileNetV3 architecture from\n",
    "    \"Searching for MobileNetV3\" <https://arxiv.org/abs/1905.02244>.\n",
    "\n",
    "    weights_link:\n",
    "    https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): number of classes\n",
    "        reduced_tail (bool): If True, reduces the channel counts of all feature layers\n",
    "            between C4 and C5 by 2. It is used to reduce the channel redundancy in the\n",
    "            backbone for Detection and Segmentation.\n",
    "    \"\"\"\n",
    "    width_multi = 1.0\n",
    "    bneck_conf = partial(InvertedResidualConfig, width_multi=width_multi)\n",
    "    adjust_channels = partial(InvertedResidualConfig.adjust_channels, width_multi=width_multi)\n",
    "\n",
    "    reduce_divider = 2 if reduced_tail else 1\n",
    "\n",
    "    inverted_residual_setting = [\n",
    "        # input_c, kernel, expanded_c, out_c, use_se, activation, stride\n",
    "        bneck_conf(16, 3, 16, 16, True, \"RE\", 2),  # C1\n",
    "        bneck_conf(16, 3, 72, 24, False, \"RE\", 2),  # C2\n",
    "        bneck_conf(24, 3, 88, 24, False, \"RE\", 1),\n",
    "        bneck_conf(24, 5, 96, 40, True, \"HS\", 2),  # C3\n",
    "        bneck_conf(40, 5, 240, 40, True, \"HS\", 1),\n",
    "        bneck_conf(40, 5, 240, 40, True, \"HS\", 1),\n",
    "        bneck_conf(40, 5, 120, 48, True, \"HS\", 1),\n",
    "        bneck_conf(48, 5, 144, 48, True, \"HS\", 1),\n",
    "        bneck_conf(48, 5, 288, 96 // reduce_divider, True, \"HS\", 2),  # C4\n",
    "        bneck_conf(96 // reduce_divider, 5, 576 // reduce_divider, 96 // reduce_divider, True, \"HS\", 1),\n",
    "        bneck_conf(96 // reduce_divider, 5, 576 // reduce_divider, 96 // reduce_divider, True, \"HS\", 1)\n",
    "    ]\n",
    "    last_channel = adjust_channels(1024 // reduce_divider)  # C5\n",
    "\n",
    "    return MobileNetV3(inverted_residual_setting=inverted_residual_setting,\n",
    "                       last_channel=last_channel,\n",
    "                       num_classes=num_classes)\n",
    "\n",
    "device = \"cuda\"\n",
    "model = mobilenet_v3_large(num_classes=1).to(device)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0639d502-8dfe-4fa2-8e6c-0bbe3ed4584a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 6.746306992494143\n",
      "Epoch 2/10, Loss: 6.218275015170757\n",
      "Epoch 3/10, Loss: 5.776793887982001\n",
      "Epoch 4/10, Loss: 5.397911702211086\n",
      "Epoch 5/10, Loss: 4.999143859514823\n",
      "Epoch 6/10, Loss: 4.532078802585602\n",
      "Epoch 7/10, Loss: 3.88519653907189\n",
      "Epoch 8/10, Loss: 3.2385766162322116\n",
      "Epoch 9/10, Loss: 2.7367376478818746\n",
      "Epoch 10/10, Loss: 2.2015660141523066\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_indx, (inputs, labels) in enumerate(loaded_train_dataset):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # Print average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / (len(loaded_train_dataset) / batch_size)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94026d2f-72d7-4079-b24c-3185b623c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities = []\n",
    "true_labels = []\n",
    "with torch.set_grad_enabled(False):\n",
    "    for batch_indx, (inputs, labels) in enumerate(loaded_val_dataset):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)      \n",
    "        outputs = model(inputs)\n",
    "        predicted_probabilities.extend(outputs.tolist())\n",
    "        true_labels.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95bc1227-3076-4057-ba78-c02b67ada459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_output(preds,labels):\n",
    "    true_labels = np.array(labels)\n",
    "    predicted_probs = np.array(preds)\n",
    "    binary_predictions = (predicted_probs >= 0.5).astype(int)\n",
    "    auc = roc_auc_score(true_labels, predicted_probs)\n",
    "    conf_matrix = confusion_matrix(true_labels, binary_predictions)\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    accuracy = accuracy_score(true_labels, binary_predictions)\n",
    "    f1 = f1_score(true_labels, binary_predictions)\n",
    "    mcc = matthews_corrcoef(true_labels, binary_predictions)  \n",
    "    return (auc, sensitivity, specificity, accuracy, f1, mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ec41ab6-c044-4807-a1b3-c723a8123d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9354838709677419 0.9696969696969697 0.8064516129032258 0.890625 0.9014084507042254 0.78977651132369\n"
     ]
    }
   ],
   "source": [
    "roc_auc, metrics_sn, metrics_sp, metrics_ACC, metrics_F1, metrics_MCC = metrics_output(predicted_probabilities, true_labels)\n",
    "print(roc_auc, metrics_sn, metrics_sp, metrics_ACC, metrics_F1, metrics_MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6d802a4-78db-4c1d-a174-efdfb218862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/root/autodl-tmp/ROC/SWE/MobileNetV3_l/y_val_pred.npy', predicted_probabilities)\n",
    "np.save('/root/autodl-tmp/ROC/SWE/MobileNetV3_l/y_val.npy', true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eae8419-0110-45ee-bc57-fcb79224c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities = []  \n",
    "true_labels = []  \n",
    "with torch.set_grad_enabled(False): \n",
    "    for batch_indx, (inputs, labels) in enumerate(loaded_test_dataset):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)    \n",
    "        outputs = model(inputs)\n",
    "        predicted_probabilities.extend(outputs.tolist())\n",
    "        true_labels.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c9cb8da-d204-444f-a832-b8e446ef28c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9906191369606003 0.9512195121951219 0.9487179487179487 0.95 0.9512195121951219 0.8999374609130707\n"
     ]
    }
   ],
   "source": [
    "roc_auc, metrics_sn, metrics_sp, metrics_ACC, metrics_F1, metrics_MCC = metrics_output(predicted_probabilities, true_labels)\n",
    "print(roc_auc, metrics_sn, metrics_sp, metrics_ACC, metrics_F1, metrics_MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a3ef595-e9b2-4fac-831a-89ecb704bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/root/autodl-tmp/ROC/SWE/MobileNetV3_l/y_test_pred.npy', predicted_probabilities)\n",
    "np.save('/root/autodl-tmp/ROC/SWE/MobileNetV3_l/y_test.npy', true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e36799-ec3e-47b2-a1ee-34e260f7b5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76f64c-0310-41a3-aff9-dbb66067bfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05f72c7-8d5d-4ce1-924a-09f158552eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
